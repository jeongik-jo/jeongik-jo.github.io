# Jeongik Cho

Ph.D. Candidate in Computer Science, Concordia University, Montreal, Canada

Email: [jeongik.jo.01@gmail.com](mailto:jeongik.jo.01@gmail.com)  
LinkedIn: [https://www.linkedin.com/in/jeongik-cho-934215254](https://www.linkedin.com/in/jeongik-cho-934215254)  
CV: [Download (PDF)](https://github.com/jeongik-jo/jeongik-jo.github.io/blob/main/Jeongik_Cho_CV.pdf)

---

## Research Interests

- Generative Models
- Generative Model Inversion (Representation Learning)
- Anomaly Detection
- Self-Supervised and Unsupervised Learning
- Theoretical Foundations of Deep Models
- Architecture-agnostic Deep Learning Algorithms

---

## Selected Publications  
> Some official versions are outdated. For updated results and experiments, refer to the summary PDFs and PhD dissertation (see [Releases](https://github.com/jeongik-jo/jeongik-jo.github.io/releases)).

1. **Training Self-supervised Class-conditional GANs with Classifier Gradient Penalty and Dynamic Prior**  
   Under review  
   - Proposed self-supervised class-conditional GAN with dynamic categorical prior and classifier gradient regularization.  
   [Preprint 1](https://vixra.org/abs/2307.0121) â€¢ [Preprint 2](https://vixra.org/abs/2409.0063)

<br>

2. **Efficient integration of perceptual Variational Autoencoder into Dynamic Latent Scale Generative Adversarial Network**  
   *Expert Systems*, 2024  
   - Combined perceptual VAE and GAN inversion for enhanced inversion performance.  
   [Short Summary (PDF)](./PVDGAN_short.pdf)  
   [Code Repository](https://github.com/jeongik-jo/PVDGAN)  
   [Published Version](https://onlinelibrary.wiley.com/doi/full/10.1111/exsy.13618)

3. **Self-supervised Out-of-distribution Detection with Dynamic Latent Scale GAN**  
   *S+SSPR*, 2022  
   - OOD (anomaly) detection method using log-probability of predicted latent vectors from GAN inversion.  
   [Short Summary (PDF)](./AnoDLSGAN_short.pdf)  
   [Code Repository](https://github.com/jeongik-jo/AnoDLSGAN)  
   [Published Version](https://link.springer.com/chapter/10.1007/978-3-031-23028-8_12)

4. **Dynamic Latent Scale for GAN Inversion**  
   *ICPRAM*, 2022  
   - Introduced a dynamic latent scaling strategy for architecture-agnostic GAN inversion with improved convergence.  
   [Short Summary (PDF)](./DLSGAN_short.pdf)  
   [Code Repository](https://github.com/jeongik-jo/DLSGAN)  
   [Published Version](https://www.scitepress.org/Link.aspx?doi=10.5220/0010816800003122)

5. **Conditional Activation GAN: Improved Auxiliary Classifier GAN**  
   *IEEE Access*, 2020  
   - Multiple GAN loss for improved class-conditional generation performance and reduced hyperparameter.  
   [Code Repository](https://github.com/jeongik-jo/CAGAN)  
   [Published Version](https://ieeexplore.ieee.org/abstract/document/9274378)

6. **Analysis of the rate of convergence of two regression estimates defined by neural features**  
   *Electronic Journal of Statistics*, 2024  
   - Proposed regression models training only output layers via regularized least squares, achieving theoretical convergence rates without backpropagation.  
   [Published Version](https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-18/issue-1/Analysis-of-the-rate-of-convergence-of-two-regression-estimates/10.1214/23-EJS2207.full)

7. **On the rate of convergence of an over-parametrized deep neural network regression estimate with ReLU activation function learned by gradient descent**  
   Under review  
   - Proved that over-parameterized ReLU networks trained by gradient descent achieve dimension-free convergence under interaction model assumptions.
---

## Dissertation

All core experiments and contributions are consolidated in the following thesis:  
ðŸ“„ **Ph.D. Dissertation** â€“ available in the [Releases section](https://github.com/jeongik-jo/jeongik-jo.github.io/releases)

---

## Technical Skills

**Languages**: Python  
**Frameworks**: PyTorch, TensorFlow, Scikit-learn  
**Topics**: Generative Models, GANs, VAEs, Diffusion Models, Anomaly Detection, Clustering, Representation Learning, Unsupervised Learning, Regression, Computer Vision, Pattern Recognition

---

For further details, please refer to the repositories above or contact me directly.
